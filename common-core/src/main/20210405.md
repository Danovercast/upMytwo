## **说说线程池**
<pre>
线程池主要工作是控制线程运行的数量,任务处理过程中创建并启动对应任务,当任务数量超出队列限制数目时,任务将进行排队等候,当其他线程运行
完毕后等待的任务再会从队列中出来执行.线程池的特点:线程复用,控制线程并发,管理线程.
  Java中通过Executor框架实现线程池，Executor、Executors、ExecutorService、ThreadPoolExecutor这几个类、接口都属于Java
  JUC包下的。创建线程池的几个重要参数，
    1.corePoolSize:线程池中核心线程大小(没有任务时线程的数量)，创建线程池后默认是没有线程的，当有任务后线程池才会创建线程，当前一个任务
    还未执行完，又新加任务时就会增加线程数目，线程数目的上限就是corePoolSize，超过上限后任务就会被暂存在队列中等待。即corePoolSize是队
    列不满时线程池中最大并行运行线程的上限。
    2.maximumPoolSize:线程池允许最大线程数，表示最大能创建多少个线程，线程池中当前线程数目不能超过该数量，若队列已满，且当前线程
    个数小于maximumPoolSize，线程池会创建新的线程来执行任务，这里值得一提的是largestPoolSize，该变量记录线程池整个生命周期中
    出现的最大线程个数。
    3.PoolSize:线程池中当前线程数量。
  通过讲述一下三者的联系来理解一下彼此的关系：当一个任务新加入线程池时，  
        1.此时corePoolSize>PoolSize: 代表此时运行的线程未达到核心线程数目，创建线程并执行该任务
        2.此时corePoolSize=PoolSize: 代表此时运行线程等于核心线程，再加一个任务就超了，会加入到等待队列中直到等待队列满了
        3.此时corePoolsize=PoolSize，且等待队列满了: 若PoolSize &lt; maximumPoolSize 则会创建新线程处理任务
        4.此时maximumPoolSize=PoolSize: 代表队列满了，且线程运行个数到达了最大值，再新加任务的话会执行拒绝策略
      PS：从上述描述可以知道三者大小关系，corePoolSize&lt;=maximumPoolSize;poolSize&lt;=maximumPoolSize;poolSize与corePoolSize
      大小关系不能一概比较。  
  
      线程池的拒绝策略：拒绝策略均需实现RejectedExecutionHandler接口方法rejectedExecution
        1.AbortPolicy，空方法，代表丢弃任务，但是会抛出RejectedExecutionException异常
        2.CallerRunsPolicy，调用入参r.run();也就是当添加到线程池中失败时由主线程来运行
        3.DiscardPolicy，空方法，丢弃任务，不会抛异常
        4.DiscardOldestPolicy，从线程池中的等待队列中取出队首元素，丢弃
        5.自定义策略，实现接口RejectedExecutionHandler的方法void rejectedExecution(Runnable r, ThreadPoolExecutor executor);
    4.keepAliveTime：空闲存活时间，线程池中的线程在多久内没有干活后停止，默认情况下这里被shutdown的线程是非corePollSize的线程，      
    5.Unit：时间单位，空闲时间的单位
    6.WorkQueue：等待队列，用于存储那些等待线程资源运行的任务，当前运行任务大于corePollSize，且队列没满的情况下，新加任务会进入队列中
    7.ThreadFactory：线程工厂，用于创建线程。
    8.Handler：线程池的拒绝策略
    
      线程池的队列：workQueue类型为BlockingQueue&lt;Runnable&gt;看名字就知道是阻塞队列了，通常可取以下三类：
        1.有界任务队列ArrayBlockingQueue，基于数组先进先出，数组嘛，创建时就要给定长度了当然是有界的了。
        2.无界任务队列LinkedBlockingQueue，基于链表先进先出，若创建时未指定链表大小，默认大小是Integer.MAX_VALUE长度的
        3.直接提交队列synchronousQueue，该队列不会保存任务，而是创建线程执行新来的任务。
          --TODO- 这个synchronousQueue有时间得搞明白来
               
  关闭线程池：ThreadPoolExecutor提供两个关闭方法，shutdown();shutdownNow();其中，shutdown方法不会立刻关闭线程池，它会等到
  缓存队列中所有任务执行完后再关闭线程池，且shutdown后便不再接受新的任务；shutdownNow会立刻终止线程池，并尝试打断正在执行的任务，
  清空等待队列返回尚未执行完的任务。shutdown方法是void的，shutdownNow方法返回值是List &lt;Runnable&gt;的        
  
  常用的线程池：
    1.newSingleThreadExecutor:创建单线程线程池，能保证加入线程池的任务顺序执行（因为该线程池提供的构造函数中无队列参数，内部实现
    给的阻塞队列是LinkedBlockingQueue）
    2.newFixedThreadPool:创建可重用固定大小的线程池，即便线程处于空闲，线程也不会被回收，除非线程池被关闭，当任务达到线程池初始化
    线程大小后，新加的任务便会进入等待队列，该队列是LinkedBlockingQueue的且是默认长度的（Integer.MAX_VALUE）
    3.newCachedThreadPool:可缓存线程池，线程数量不定，且最大线程是Integer.MAX_VALUE;如果线程池长度超过处理需要，可灵活回收线程，
    若无可回收线程，则创建新线程。线程池中的空闲线程有keepAliveTime，60s，此类线程池适合大量耗时小的任务。
    4.newScheduledThreadPool:创建定长线程池，支持定时、周期性的执行。适用于定时任务        
    
  一个任务从被提交到被执行，线程池做了哪些工作?
  
</pre>

## **关于锁**
<pre>
Java并发体系中的锁。七类：
1.偏向锁、轻量锁、重量锁
2.可重入锁、非可重入锁
3.共享锁、独占锁
4.公平锁、非公平锁
5.悲观锁、乐观锁
6.自旋锁、非自旋锁
7.可中断锁、不可中断锁
    1
    偏向锁：当锁不存在竞争时，该锁就没u存在的必要，只需打上个标记，这个步骤由jvm来执行。一个对象初始后还没有任何线程来获取它的锁的时候
  这个锁就可能是偏向的，当有第一个线程来获取的时候，它就将对应线程记录下来，以后如果来获取锁的是该记录线程就可以直接获取对应锁，开销更小。
    轻量锁：JVM开发者很多情况下，synchronized中代码是被多个线程交替执行的，而不是同时执行的，也就是说不存在竞争关系，或者竞争时间短，用
  CAS操作就能解决，没必要用synchronized重量锁，轻量锁是指当锁原来是偏向锁的时候，被另外线程访问了，说明存在竞争，那么偏向锁就会升级为
  轻量锁，线程通过自选操作等待获取锁资源，而非阻塞
    重量锁：互斥锁，利用操作系统的同步机制实现，开销较大，当多个线程存在实际竞争关系且竞争时间长时，轻量级锁满足不了要求，锁会膨胀为重量锁
  让其他申请但拿不到锁的线程阻塞。
    锁升级：无锁--偏向锁--轻量锁--重量锁
    2
    可重入锁：ReentrantLock，当前线程若已持有当前请求资源的锁时，能在不释放锁的情况下直接获取对应资源的锁；相反不可重入锁是即便当前对
    像以有请求资源的锁时也需要先释放对应锁才能再获取锁。
    3
    共享锁：一把锁可以被多个线程同时获得，独占锁：同一时刻只能有一个线程获得锁；按读写锁的方式来理解
    4
    公平锁：在等待锁资源的的情况下，公平锁会根据等待队列的顺序决定应该给哪个线程锁，非公平锁：先等待的线程不一定能优先获取锁
    5
    悲观锁：悲观锁认为数据一定存在竞争，所以要在获取资源之前拿到锁，进行独占；乐观锁不同，乐观锁认为数据不一定被改变，只有在改写数据的
    时候才会尝试锁住资源。乐观锁通过CAS的操作对数据进行更新修改。
    6
    不可中断锁：一旦申请获得锁成功，其他资源便只能等待拥有锁的线程释放锁，不能进行中断去做其他事情，也就是被阻塞；而可中断锁不同，在等待
    锁资源的时候，它允许停止获取锁进行中断获取锁的操作，转而进行其他操作。
   
</pre>

## **ReentrantLock使用场景**
<pre>
1.耗时操作重复点击提交。根据ReentrantLock.tryLock()状态决定是否继续操作。
2.阻塞执行，类似于synchronized，防止资源冲突，保证同一时刻只有一个线程可操作资源，适用于资源的竞争（读写文件、消息发送），可通过
lock.lock();阻塞程序运行
3.当锁被其他线程拿着的时候等待一段时间，等不到则不再获取锁，通过lock.tryLock(long,timeUnit);实现
4.运行一段程序，当发现该操作正在进行中则等待执行，期间可中断正在进行的操作立刻释放锁继续下一操作。这也是ReentrantLock与synchronized不
同的一个地方，是否可中断。lock.lockInterruptibly();

</pre>

````java
//耗时操作重复点击
//共享资源：
 class RR implements Runnable{
   private ReentrantLock lock=new ReentrantLock();
   public void run (){
     if(lock.tryLock()){
       //当前线程拿到了锁
       sout(Thread.current.getName());
       lock.unLock();
     }
   }
 }
// 资源请求类：
 class Test{
  psvm(){
    RR r=new RR();
    Thread t1=new Thread(r);
    Thread t2=new Thread(r);
    Thread t3=new Thread(r);
    t1.start();
    t2.start();
    t3.start();
  }
 }
 //输出结果：只要电脑CPU多核且运行速度足够，就只会打印一条，可在主线程start前进行sleep或者在RR类中tryLock加上超时时间

````

## **死锁条件**
<pre>
1.互斥；2.占有和保持；3.不可剥夺；4.循环等待
</pre>

## **AQS**  TODO 没整明白
<pre>
AQS：AbstractQueuedSynchronizer，抽象队列同步器，实现了对同步状态的管理，及对阻塞线程进行排队，等待通知等。AQS的核心包括：同步队
列、独占锁的获取与释放，共享锁的获取与释放，可中断锁，超时锁等。AQS是个抽象类，只作为一个模板（但很多性质顶层已经实现好了），当我们继承AQS去实现
自己的同步器时，要做的是根据自己同步器需要满足的性质来实现线程获取和释放资源的方式（修改同步状态变量的方式），至于具体线程等待队列的维护（如
资源获取失败入队，唤醒出队，线程在队列中的行为管理等）AQS已经实现了，这是AQS作为模板方法的实现。
AQS支持两种模式：独占与共享模式。独占：同一时刻只允许一个线程访问共享资源，如ReentrantLock，synchronized；独占又分公平/非公平；共享模式：
同一时刻允许多个线程访问共享资源。
AQS维护两个队列，一个是AQS类维护的CLH队列，一个是内部类ConditionObject维护的Condition队列（用于支持线程之间的同步，提供await、signal、signalAll方法）
AQS使用CLH内部队列，又成CLH锁（人名开头），该锁是基于链表的可扩展、高性能、公平的自旋锁，申请线程只能在本地变量上自旋，通过轮询前驱的状态，若
前驱释放了锁，则结束当前线程的自旋状态。
           +------+  prev +-----+       +-----+
      head |      | <---- |     | <---- |     |  tail
           +------+       +-----+       +-----+
 
</pre>

## **AtomicInteger的实现**
<pre>
AtomicInteger是对int的一个封装，提供原子性的访问和更新，多线程环境执行原子类的方法时，具有排他性，即某一时间段内，方法内的程序只会被其中一个线程
执行，其它线程进入自旋，自旋通常是执行一段无意义的代码，原子性的操作是基于CAS（Compare and Set），AtomicXXX类都依赖于UnSafe类提供的一些操作
以volatile的value字段记录数值，保证可见性，UnSafe类利用value字段的内存地址偏移完成操作，CAS操作涉及CAS指令，这部份实际涉及操作系统指令，大多数
操作系统上CAS指令是个非常轻量级的操作。
</pre>

## **乐观锁与悲观锁**
<pre>
CPU是时分复用的，CPU的时间片会被分配给不同的线程/进程轮流执行，时间片与时间片之间需要CPU进行调度切换，即发生进程的切换，切换涉及清空寄存器、缓存
数据，然后重新加载新的Thread所需数据，当一个线程被挂起时，进入阻塞队列，在一定时间或条件下，被其它线程通过notify();notifyAll();唤醒。当某个线程
存在某些资源不可获取或者资源不可用的情况下就会让出CPU，将当前线程状态改为阻塞状态，等到资源可用了，再将线程唤醒进入runnable状态，等待CPU调度，
这就是典型的悲观锁的实现，独占锁便是一种悲观锁，synchronized时典型的独占锁，它假设最坏的情况，确保运行线程不被其他线程干扰，会导致其它线程挂起，
等待持有锁的线程释放锁。
  但是进程从挂起到恢复执行过程中增加了额外的开销，线程等待时无法进行其它操作，考虑这样一个场景，在取得锁资源后执行不复杂不耗时的操作，线程A，B
  竞争锁资源，先是A拿到资源，上锁，紧接着B请求资源，发现拿不到锁，进入阻塞挂起，同时A释放了锁，B发现了，需要从阻塞状态恢复，然后抢占锁，这样就
  增大时间开销了。
那么如果我们不加锁，而是假设没有冲突，而去完成某项操作，如果发现冲突，那么久让本次操作失败，然后重试，这样线程就不用让出CPU，通过while循环执行，
直到成功，这样在竞争不激烈的情况下减少了因为切换线程状态的开销，这就是乐观锁。CAS就是乐观锁的一种实现。  
  CAS：Compare And Set，比较并设置，很多CPU直接支持CAS指令，多个线程尝试使用CAS同时更新共享资源时，只有一个线程能够成功，其它的失败，失败的线程
  不会被挂起，而是被告知本次更新失败，且可以重试，CAS有三个操作数：内存值A，期望值B，更新值C。仅当期望值B与内存值A相等时，才会为内存值更新为C，
  否则什么也不做，但这样同样存在ABA问题，即 内存值被更新过两次，开始是B，后被其它线程更为C，再被其它线程更为B，这样根据CAS的三个操作数来看的话，
  表面上是符合更新条件的，但实际上内存值已经被修改过了，可以增加实际戳/版本号一起比较，每次更新都会修改增加版本号或时间戳。
  
</pre>

## **volatile关键字**
<pre>
被volatile修饰的变量具有特性：1.保证变量对其他线程的可见性；2.禁止对与volatile修饰的变量进行有关指令重排
1.可见性：volatile能够保证当一个线程修改了变量的值后立刻将修改后的值写入主存。volatile变量的访问规则：使用前必须从主内存刷新最新值；修改后要
立刻同步主内存。
2.禁止指令重排优化：虚拟机会为了减少因为内存操作导致的CPU时间片闲置进行指令重排，这个重排是指单线程环境在不影响最终结果的前提下对运算指令进行
重排。
由于volatile只能保证可见性 不能保证原子性，仅基于volatile的变量运算是线程不安全的，它能保证线程在读取该变量的那一刻数据是正确的，但各线程从中
读取后执行其它操作（更新，或者准备写进主存）但尚未写回到主存中，其它线程对变量进行了修改，这种情况便存在问题了。
  volatile使用的场景：运算结果不依赖变量当前值（也就是不会用该值参与运算），或者能保证只有单一的线程修改变量的值。这样理解：多个变量之间或某
  个变量修改前后没有约束。要使volatileb变量提供线程安全需满足下面条件：1.对变量写操作不依赖当前值；2.该变量未包含在具有其它变量的不变式中。
  白话就是在对变量修改的时候不会先判断一下 xx=多少或者xx！=多少然后再对xx进行赋值修改；volatile不适用于【读取-修改-写入】的场景
 volatile一个很适合的场景：
  private volatile ifShutDown=false;
  void shutDownNow(){ifShutDown=true;}
  void doWork(){
    while(!ifShutDown){
      //do work;
    }
  }
  
</pre>

## **ThreadLocal**
<pre>
ThreadLocal太重要了，以至于我忘了，这里再整一遍加深一下印象，从ThreadLocal、Thread、ThreadLocalMap三个class的结构开始。ThreadLocal：是我们
new创建的对象，一个类中我们能创建多个ThreadLocal对象，ThreadLocalMap是ThreadLocal的内部类，ThreadLocalMap类似于Map，使用Entry[]数组存储数
据，Entry对象继承虚引用的ThreadLocal，然后Entry对象有个Object属性作为map的value，容易看出，key的类型是WeakReference&lt;ThreadLocal&gt;,
value的类型是Object，ThreadLocalMap存储在Thread中，即Thread有个ThreadLocalMap类型的属性，这样就能理解三者的关系了。在一个类中创建多个不同的
ThreadLocal对象，通过ThreadLocal的set(Object)方法向ThreadLocal写入value，ThreadLoca会获取当前线程的ThreadLocalMap，然后将ThreadLocal对象
作为key新的value作为值，存入对应Thread的ThreadLocalMap中。
  再从内存存储结构来理解一下三者的关系，对象创建存储在堆内存属于线程共享，线程运行有其独立空间--栈，栈中持有堆中对象的引用但不持有对象本身，
  得出Thread的reference指向堆中Thread，堆中Thread持有ThreadLocalMap对象，ThreadLocalMap又持有Entry&lt;WeakReference&gt;数组数组中
  存储key-value，其中key又是ThreadLocal对象，这样就能解释为什么Entry中key是WeakReference的了。
  
 ThreadLocal在内存哪一块?如果是指对象，那当然是在堆内存，如果是指引用那当然是在栈内存。ThreadLocal被线程中ThreadLocalMap属性的Entry属性的
 WeakReference&lt;ThreadLocal&gt;
</pre>

## **Java NIO**
<pre>

</pre>













