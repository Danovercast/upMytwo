## **说说线程池**
<pre>
线程池主要工作是控制线程运行的数量,任务处理过程中创建并启动对应任务,当任务数量超出队列限制数目时,任务将进行排队等候,当其他线程运行
完毕后等待的任务再会从队列中出来执行.线程池的特点:线程复用,控制线程并发,管理线程.
  Java中通过Executor框架实现线程池，Executor、Executors、ExecutorService、ThreadPoolExecutor这几个类、接口都属于Java
  JUC包下的。创建线程池的几个重要参数，
    1.corePoolSize:线程池中核心线程大小(没有任务时线程的数量)，创建线程池后默认是没有线程的，当有任务后线程池才会创建线程，当前一个任务
    还未执行完，又新加任务时就会增加线程数目，线程数目的上限就是corePoolSize，超过上限后任务就会被暂存在队列中等待。即corePoolSize是队
    列不满时线程池中最大并行运行线程的上限。
    2.maximumPoolSize:线程池允许最大线程数，表示最大能创建多少个线程，线程池中当前线程数目不能超过该数量，若队列已满，且当前线程
    个数小于maximumPoolSize，线程池会创建新的线程来执行任务，这里值得一提的是largestPoolSize，该变量记录线程池整个生命周期中
    出现的最大线程个数。
    3.PoolSize:线程池中当前线程数量。
  通过讲述一下三者的联系来理解一下彼此的关系：当一个任务新加入线程池时，  
        1.此时corePoolSize>PoolSize: 代表此时运行的线程未达到核心线程数目，创建线程并执行该任务
        2.此时corePoolSize=PoolSize: 代表此时运行线程等于核心线程，再加一个任务就超了，会加入到等待队列中直到等待队列满了
        3.此时corePoolsize=PoolSize，且等待队列满了: 若PoolSize &lt; maximumPoolSize 则会创建新线程处理任务
        4.此时maximumPoolSize=PoolSize: 代表队列满了，且线程运行个数到达了最大值，再新加任务的话会执行拒绝策略
      PS：从上述描述可以知道三者大小关系，corePoolSize&lt;=maximumPoolSize;poolSize&lt;=maximumPoolSize;poolSize与corePoolSize
      大小关系不能一概比较。  
  
      线程池的拒绝策略：拒绝策略均需实现RejectedExecutionHandler接口方法rejectedExecution
        1.AbortPolicy，空方法，代表丢弃任务，但是会抛出RejectedExecutionException异常
        2.CallerRunsPolicy，调用入参r.run();也就是当添加到线程池中失败时由主线程来运行
        3.DiscardPolicy，空方法，丢弃任务，不会抛异常
        4.DiscardOldestPolicy，从线程池中的等待队列中取出队首元素，丢弃
        5.自定义策略，实现接口RejectedExecutionHandler的方法void rejectedExecution(Runnable r, ThreadPoolExecutor executor);
    4.keepAliveTime：空闲存活时间，线程池中的线程在多久内没有干活后停止，默认情况下这里被shutdown的线程是非corePollSize的线程，      
    5.Unit：时间单位，空闲时间的单位
    6.WorkQueue：等待队列，用于存储那些等待线程资源运行的任务，当前运行任务大于corePollSize，且队列没满的情况下，新加任务会进入队列中
    7.ThreadFactory：线程工厂，用于创建线程。
    8.Handler：线程池的拒绝策略
    
      线程池的队列：workQueue类型为BlockingQueue&lt;Runnable&gt;看名字就知道是阻塞队列了，通常可取以下三类：
        1.有界任务队列ArrayBlockingQueue，基于数组先进先出，数组嘛，创建时就要给定长度了当然是有界的了。
        2.无界任务队列LinkedBlockingQueue，基于链表先进先出，若创建时未指定链表大小，默认大小是Integer.MAX_VALUE长度的
        3.直接提交队列synchronousQueue，该队列不会保存任务，而是创建线程执行新来的任务。
          --TODO- 这个synchronousQueue有时间得搞明白来
               
  关闭线程池：ThreadPoolExecutor提供两个关闭方法，shutdown();shutdownNow();其中，shutdown方法不会立刻关闭线程池，它会等到
  缓存队列中所有任务执行完后再关闭线程池，且shutdown后便不再接受新的任务；shutdownNow会立刻终止线程池，并尝试打断正在执行的任务，
  清空等待队列返回尚未执行完的任务。shutdown方法是void的，shutdownNow方法返回值是List &lt;Runnable&gt;的        
  
  常用的线程池：
    1.newSingleThreadExecutor:创建单线程线程池，能保证加入线程池的任务顺序执行（因为该线程池提供的构造函数中无队列参数，内部实现
    给的阻塞队列是LinkedBlockingQueue）
    2.newFixedThreadPool:创建可重用固定大小的线程池，即便线程处于空闲，线程也不会被回收，除非线程池被关闭，当任务达到线程池初始化
    线程大小后，新加的任务便会进入等待队列，该队列是LinkedBlockingQueue的且是默认长度的（Integer.MAX_VALUE）
    3.newCachedThreadPool:可缓存线程池，线程数量不定，且最大线程是Integer.MAX_VALUE;如果线程池长度超过处理需要，可灵活回收线程，
    若无可回收线程，则创建新线程。线程池中的空闲线程有keepAliveTime，60s，此类线程池适合大量耗时小的任务。
    4.newScheduledThreadPool:创建定长线程池，支持定时、周期性的执行。适用于定时任务        
    
  一个任务从被提交到被执行，线程池做了哪些工作?
  
</pre>

## **关于锁**
<pre>
Java并发体系中的锁。七类：
1.偏向锁、轻量锁、重量锁
2.可重入锁、非可重入锁
3.共享锁、独占锁
4.公平锁、非公平锁
5.悲观锁、乐观锁
6.自旋锁、非自旋锁
7.可中断锁、不可中断锁
    1
    偏向锁：当锁不存在竞争时，该锁就没u存在的必要，只需打上个标记，这个步骤由jvm来执行。一个对象初始后还没有任何线程来获取它的锁的时候
  这个锁就可能是偏向的，当有第一个线程来获取的时候，它就将对应线程记录下来，以后如果来获取锁的是该记录线程就可以直接获取对应锁，开销更小。
    轻量锁：JVM开发者很多情况下，synchronized中代码是被多个线程交替执行的，而不是同时执行的，也就是说不存在竞争关系，或者竞争时间短，用
  CAS操作就能解决，没必要用synchronized重量锁，轻量锁是指当锁原来是偏向锁的时候，被另外线程访问了，说明存在竞争，那么偏向锁就会升级为
  轻量锁，线程通过自选操作等待获取锁资源，而非阻塞
    重量锁：互斥锁，利用操作系统的同步机制实现，开销较大，当多个线程存在实际竞争关系且竞争时间长时，轻量级锁满足不了要求，锁会膨胀为重量锁
  让其他申请但拿不到锁的线程阻塞。
    锁升级：无锁--偏向锁--轻量锁--重量锁
    2
    可重入锁：ReentrantLock，当前线程若已持有当前请求资源的锁时，能在不释放锁的情况下直接获取对应资源的锁；相反不可重入锁是即便当前对
    像以有请求资源的锁时也需要先释放对应锁才能再获取锁。
    3
    共享锁：一把锁可以被多个线程同时获得，独占锁：同一时刻只能有一个线程获得锁；按读写锁的方式来理解
    4
    公平锁：在等待锁资源的的情况下，公平锁会根据等待队列的顺序决定应该给哪个线程锁，非公平锁：先等待的线程不一定能优先获取锁
    5
    悲观锁：悲观锁认为数据一定存在竞争，所以要在获取资源之前拿到锁，进行独占；乐观锁不同，乐观锁认为数据不一定被改变，只有在改写数据的
    时候才会尝试锁住资源。乐观锁通过CAS的操作对数据进行更新修改。
    6
    不可中断锁：一旦申请获得锁成功，其他资源便只能等待拥有锁的线程释放锁，不能进行中断去做其他事情，也就是被阻塞；而可中断锁不同，在等待
    锁资源的时候，它允许停止获取锁进行中断获取锁的操作，转而进行其他操作。
   
</pre>

## **ReentrantLock使用场景**
<pre>
1.耗时操作重复点击提交。根据ReentrantLock.tryLock()状态决定是否继续操作。
2.阻塞执行，类似于synchronized，防止资源冲突，保证同一时刻只有一个线程可操作资源，适用于资源的竞争（读写文件、消息发送），可通过
lock.lock();阻塞程序运行
3.当锁被其他线程拿着的时候等待一段时间，等不到则不再获取锁，通过lock.tryLock(long,timeUnit);实现
4.运行一段程序，当发现该操作正在进行中则等待执行，期间可中断正在进行的操作立刻释放锁继续下一操作。这也是ReentrantLock与synchronized不
同的一个地方，是否可中断。lock.lockInterruptibly();

</pre>

````java
//耗时操作重复点击
//共享资源：
 class RR implements Runnable{
   private ReentrantLock lock=new ReentrantLock();
   public void run (){
     if(lock.tryLock()){
       //当前线程拿到了锁
       sout(Thread.current.getName());
       lock.unLock();
     }
   }
 }
// 资源请求类：
 class Test{
  psvm(){
    RR r=new RR();
    Thread t1=new Thread(r);
    Thread t2=new Thread(r);
    Thread t3=new Thread(r);
    t1.start();
    t2.start();
    t3.start();
  }
 }
 //输出结果：只要电脑CPU多核且运行速度足够，就只会打印一条，可在主线程start前进行sleep或者在RR类中tryLock加上超时时间

````

## **死锁条件**
<pre>
1.互斥；2.占有和保持；3.不可剥夺；4.循环等待
</pre>

## **AQS**  TODO 没整明白
<pre>
AQS：AbstractQueuedSynchronizer，抽象队列同步器，实现了对同步状态的管理，及对阻塞线程进行排队，等待通知等。AQS的核心包括：同步队
列、独占锁的获取与释放，共享锁的获取与释放，可中断锁，超时锁等。AQS是个抽象类，只作为一个模板（但很多性质顶层已经实现好了），当我们继承AQS去实现
自己的同步器时，要做的是根据自己同步器需要满足的性质来实现线程获取和释放资源的方式（修改同步状态变量的方式），至于具体线程等待队列的维护（如
资源获取失败入队，唤醒出队，线程在队列中的行为管理等）AQS已经实现了，这是AQS作为模板方法的实现。
AQS支持两种模式：独占与共享模式。独占：同一时刻只允许一个线程访问共享资源，如ReentrantLock，synchronized；独占又分公平/非公平；共享模式：
同一时刻允许多个线程访问共享资源。
AQS维护两个队列，一个是AQS类维护的CLH队列，一个是内部类ConditionObject维护的Condition队列（用于支持线程之间的同步，提供await、signal、signalAll方法）
AQS使用CLH内部队列，又成CLH锁（人名开头），该锁是基于链表的可扩展、高性能、公平的自旋锁，申请线程只能在本地变量上自旋，通过轮询前驱的状态，若
前驱释放了锁，则结束当前线程的自旋状态。
           +------+  prev +-----+       +-----+
      head |      | <---- |     | <---- |     |  tail
           +------+       +-----+       +-----+
 
</pre>

## **AtomicInteger的实现**
<pre>
AtomicInteger是对int的一个封装，提供原子性的访问和更新，多线程环境执行原子类的方法时，具有排他性，即某一时间段内，方法内的程序只会被其中一个线程
执行，其它线程进入自旋，自旋通常是执行一段无意义的代码，原子性的操作是基于CAS（Compare and Set），AtomicXXX类都依赖于UnSafe类提供的一些操作
以volatile的value字段记录数值，保证可见性，UnSafe类利用value字段的内存地址偏移完成操作，CAS操作涉及CAS指令，这部份实际涉及操作系统指令，大多数
操作系统上CAS指令是个非常轻量级的操作。
</pre>

## **乐观锁与悲观锁**
<pre>
CPU是时分复用的，CPU的时间片会被分配给不同的线程/进程轮流执行，时间片与时间片之间需要CPU进行调度切换，即发生进程的切换，切换涉及清空寄存器、缓存
数据，然后重新加载新的Thread所需数据，当一个线程被挂起时，进入阻塞队列，在一定时间或条件下，被其它线程通过notify();notifyAll();唤醒。当某个线程
存在某些资源不可获取或者资源不可用的情况下就会让出CPU，将当前线程状态改为阻塞状态，等到资源可用了，再将线程唤醒进入runnable状态，等待CPU调度，
这就是典型的悲观锁的实现，独占锁便是一种悲观锁，synchronized时典型的独占锁，它假设最坏的情况，确保运行线程不被其他线程干扰，会导致其它线程挂起，
等待持有锁的线程释放锁。
  但是进程从挂起到恢复执行过程中增加了额外的开销，线程等待时无法进行其它操作，考虑这样一个场景，在取得锁资源后执行不复杂不耗时的操作，线程A，B
  竞争锁资源，先是A拿到资源，上锁，紧接着B请求资源，发现拿不到锁，进入阻塞挂起，同时A释放了锁，B发现了，需要从阻塞状态恢复，然后抢占锁，这样就
  增大时间开销了。
那么如果我们不加锁，而是假设没有冲突，而去完成某项操作，如果发现冲突，那么久让本次操作失败，然后重试，这样线程就不用让出CPU，通过while循环执行，
直到成功，这样在竞争不激烈的情况下减少了因为切换线程状态的开销，这就是乐观锁。CAS就是乐观锁的一种实现。  
  CAS：Compare And Set，比较并设置，很多CPU直接支持CAS指令，多个线程尝试使用CAS同时更新共享资源时，只有一个线程能够成功，其它的失败，失败的线程
  不会被挂起，而是被告知本次更新失败，且可以重试，CAS有三个操作数：内存值A，期望值B，更新值C。仅当期望值B与内存值A相等时，才会为内存值更新为C，
  否则什么也不做，但这样同样存在ABA问题，即 内存值被更新过两次，开始是B，后被其它线程更为C，再被其它线程更为B，这样根据CAS的三个操作数来看的话，
  表面上是符合更新条件的，但实际上内存值已经被修改过了，可以增加实际戳/版本号一起比较，每次更新都会修改增加版本号或时间戳。
  
</pre>

## **volatile关键字**
<pre>
被volatile修饰的变量具有特性：1.保证变量对其他线程的可见性；2.禁止对与volatile修饰的变量进行有关指令重排
1.可见性：volatile能够保证当一个线程修改了变量的值后立刻将修改后的值写入主存。volatile变量的访问规则：使用前必须从主内存刷新最新值；修改后要
立刻同步主内存。
2.禁止指令重排优化：虚拟机会为了减少因为内存操作导致的CPU时间片闲置进行指令重排，这个重排是指单线程环境在不影响最终结果的前提下对运算指令进行
重排。
由于volatile只能保证可见性 不能保证原子性，仅基于volatile的变量运算是线程不安全的，它能保证线程在读取该变量的那一刻数据是正确的，但各线程从中
读取后执行其它操作（更新，或者准备写进主存）但尚未写回到主存中，其它线程对变量进行了修改，这种情况便存在问题了。
  volatile使用的场景：运算结果不依赖变量当前值（也就是不会用该值参与运算），或者能保证只有单一的线程修改变量的值。这样理解：多个变量之间或某
  个变量修改前后没有约束。要使volatileb变量提供线程安全需满足下面条件：1.对变量写操作不依赖当前值；2.该变量未包含在具有其它变量的不变式中。
  白话就是在对变量修改的时候不会先判断一下 xx=多少或者xx！=多少然后再对xx进行赋值修改；volatile不适用于【读取-修改-写入】的场景
 volatile一个很适合的场景：
  private volatile ifShutDown=false;
  void shutDownNow(){ifShutDown=true;}
  void doWork(){
    while(!ifShutDown){
      //do work;
    }
  }
  
</pre>

## **ThreadLocal**
<pre>
ThreadLocal太重要了，以至于我忘了，这里再整一遍加深一下印象，从ThreadLocal、Thread、ThreadLocalMap三个class的结构开始。ThreadLocal：是我们
new创建的对象，一个类中我们能创建多个ThreadLocal对象，ThreadLocalMap是ThreadLocal的内部类，ThreadLocalMap类似于Map，使用Entry[]数组存储数
据，Entry对象继承虚引用的ThreadLocal，然后Entry对象有个Object属性作为map的value，容易看出，key的类型是WeakReference&lt;ThreadLocal&gt;,
value的类型是Object，ThreadLocalMap存储在Thread中，即Thread有个ThreadLocalMap类型的属性，这样就能理解三者的关系了。在一个类中创建多个不同的
ThreadLocal对象，通过ThreadLocal的set(Object)方法向ThreadLocal写入value，ThreadLoca会获取当前线程的ThreadLocalMap，然后将ThreadLocal对象
作为key新的value作为值，存入对应Thread的ThreadLocalMap中。
  再从内存存储结构来理解一下三者的关系，对象创建存储在堆内存属于线程共享，线程运行有其独立空间--栈，栈中持有堆中对象的引用但不持有对象本身，
  得出Thread的reference指向堆中Thread，堆中Thread持有ThreadLocalMap对象，ThreadLocalMap又持有Entry&lt;WeakReference&gt;数组数组中
  存储key-value，其中key又是ThreadLocal对象，这样就能解释为什么Entry中key是WeakReference的了。
  
 ThreadLocal在内存哪一块?如果是指对象，那当然是在堆内存，如果是指引用那当然是在栈内存。ThreadLocal被线程中ThreadLocalMap属性的Entry属性的
 WeakReference&lt;ThreadLocal&gt;
</pre>

## **Java BIO NIO**
<pre>
NIO: 又称Non-Blocking IO、new IO，属于一种同步非阻塞IO模型，也是IO多路复用的基础，解决并发与IO处理问题。
先说说传统IO，与NIO相比BIO(Blocking-IO)，阻塞IO的经典代码：
======服务器端start=======
{
ExecutorService executor=Executors.newFixedExecutorService(100);
ServerSocket serverSocket=new ServerSocket();
serverSocket.bind(new InetSocketAddress("localhost",8088));
while(!Thread.currentThread.isInterrupted()){
  //主线程循环等待连接的到来
  Socket socket = serverSocket.accept();
  executor.sumbmit(new ConnectHandler(socket));
}
//线程处理连接
class ConnectHandler extends Thread{
  private Socket socket;
  private byte[]bytes;
  public ConnectHandler(Socket socket){
    this.socket=socket;
  }
  public void run(){
    while(!Thread.currentThread.isInterrupted()&&!socket.isClose()){
      socket.getInputStream().read(bytes);//接收客户端的input内容
      socket.close();
    }
    sout(new String(bytes));
  }
}
}
======服务器端end=======

======客户端start======
{
Socket socket=new Socket();
SocketAddress socketAddress=InetSocketAddress("localhost",8088);
socket.connect(socketAddress);
OutputStream outputStream = socket.getOutputStream();
outputStream.write("hello".getBytes(StandardCharsets.UTF-8));
}
======客户端end======
上述连接是每个连接对应一个线程的模型，使用线程的原因是因为socket.accept(),socket.getInputStream.read,socket.getOutputStream.wirte()是同步阻
塞的当一个连接在处理I/O时系统是阻塞的，若系统是单线程的话必然挂起等待阻塞，但是CPU是被释放出来的，使用多线程就能让CPU的使用效率更高，这也是多线程的
本质:利用多核；当I/O阻塞系统，但CPU空闲时可以利用多线程充分利用CPU资源。 现在 多线程一般都使用线程池，可以让线程创建及回收成本降低，在活动连接数不
是很高的情况下（小于单机一千），可以让每个连接专注于自己的I/O且编程简单，也不用过多考虑系统过载、限流等问题，线程池本身就是一个天然漏斗，能缓冲一些
系统处理不了的连接或者请求。不过这类模型很依赖线程，而大多数情况下，线程又是较宝贵的资源：
  1.线程的创建销毁成本较高，linux操作系统中，线程本质就是一个进程，创建和销毁都属于重量级系统函数 
  2.线程本身占用较大内存，像Java线程栈，一般至少分配512k-1M的内存空间，当线程开辟过千，那累加起来消耗的内存也是相当可观的，会占据大半JVM内存
  3.线程之间的切换成本也是较大的，操作系统线程切换时，需要保留线程的上下文，然后执行系统调用，如果线程数目太多，可能执行线程切换的时间甚至大于线程
  实际执行时间，这时候带来的表现往往是系统load偏高，CPU 使用率特高（20%以上）导致系统几乎可用
  4.容易造成锯齿状系统负载，因为系统负载是用核心CPU数或者活动线程数。一旦线程数量高但外部环境不稳定时就很容易造成大量线程同时返回，然后阻塞，导致
  系统负载压力过大从而系统不可用。
  
 所有系统IO都分两个阶段：等待就绪和操作。例：读函数分等待系统可读以及读 两个阶段；写函数分等待资源可写以及真正的写。其中等待就绪这个过程是不占用CPU
 的，是在"空等";而真正的读写操作的阻塞是使用CPU的，且这个过程是很快的，属于memory copy，是基于内存操作的，可理解为基本不耗时。
 
 以socket.read()为例：传统BIO socket.read();当TCP RecvBuffer中没有数据时函数会阻塞，知道接收到数据，然后返回数据。对于NIO而言，如果TCP RecvBuffer
 有数据，就从网卡中读取数据到内存，并返回给用户，反之直接返回0，不会阻塞。最新AIO(Async I/O)中会进一步，不光等待数据是异步的，连数据从网卡到内存也是
 异步的。这样理解：BIO关注的是要读要写，不能读或写就呆等；NIO关注的是能读了、能写了，不能的这段时间里允许进行其它的工作；AIO关注的是读完了。
 NIO的一个重要特点是:socket的主要读、写、注册、接收函数在等待就绪阶段都是非阻塞的，实际上IO操作是同步阻塞的(这个步骤会消耗CPU但是会很快)。
 
 结合事件模型使用NIO同步非阻塞模型：之前BIO使用线程池进行操作了，BIO我们无法知道什么时候能写、能读只有两个阻塞函数：socket.read();socket.write();
 这两个函数无法进行有效的中断，所以我们通过线程池来提高CPU利用率。
 NIO的读写函数会立刻返回，有鉴于此我们可以考虑这样：若一个连接不能读、写（socket.read();socket.wirte();返回0)，我们可以将这件事记录，记录的方式
 通常是在selector上注册标记位，然后切换到其它就绪的连接(channel)继续读写。
 利用事件模型单线程处理所有IO请求：NIO主要有几个事件：都就绪、写就绪、有新连接到来。我们需要先注册对某件事情感兴趣的处理器，在合适的时机告诉处理器，
 对这件事情标识关注。如对于写操作，就是对写不出去的时候感兴趣；对于读操作，就是完成连接和系统无法承载新读入数据的时候；对于server端accept，一般是服
 务端刚启动；对于connect，一般是connect失败需要重连或直接异步调用connect的时候。
 ps：select是阻塞的，无论是通过操作系统的通知（epoll）还是轮询（select、poll），这个函数是阻塞的，所以可以安全的在一个while loop里调用该函数，而
 不必关心CPU空转。
 
 NIO由原来阻塞读写(占用线程)变成单线程轮询事件，找到可以读写的网络描述符进行读写，除了事件轮询是阻塞的，剩余的IO都是纯CPU操作，故而不需开新线程。且
 减少了线程的数量，减少了切换线程的开销。单线程因为不需切换线程处理IO的效率高，只负责读、写、选择事件，但是现在的服务器一般都是多核的，如果能利用多
 核进行IO，来分析一下我们需要的线程，其中主要包括 1.事件分发器，单线程选择就绪的事件。2.IO处理器，包括connect、read、write等此类纯CPU操作。3.业务
 线程，在处理完IO后，业务一般还会有自己的逻辑，有的还有其它阻塞IO，如DB操作、RPC操作，只要有阻塞就需要单独的线程。
   Java的Selector对于Linux来说有个限制，同y一个channel的select不能被并发调用，因此如果有多个IO线程，必须保证，一个socket只能属于一个IOThread
   一个IOThread能够使用多个Socket。
   
  另外连接的处理与读写的处理通常不放在一起，可以选择分开，这样对于大量连接的注册、读写就可以分发。NIO的read、write虽然是非阻塞的函数，但毕竟占用
  CPU。 
   
 
</pre>

<h6>传统IO模型</h6>
![](file/normal_IO_model.png)


<h6>优化线程模型</h6>
![](file/optimise_Thread_Model.png)


## **Java NIO**
<pre>
NIO的三大核心部分：Channel、Buffer、Selector。传统IO面向字节流字符流操作NIO面向缓冲区，NIO基于Channel、Buffer，数据从channel读到buffer，或者从
buffer写到channel中；Selector用于监听多个通道的事件(连接的打开，数据的到达)，即Selector可监听多个channel。这样理解，一个线程可以处理多个NIO（包
括读、写）当某通道发起读请求时，线程尝试读，若状态不是读就绪的话，该线程也不会阻塞，它可以尝试进行其它通道的读或写，写则相同。
  Channel：channel应当与Stream是同级的，但Stream是单向的，Channel是双向的，channel既可以读又可以写。NIO的主要实现有FileChannel、DatagramChannel、
  SocketChannel、ServerSocketChannel。
  Buffer：这个很好理解、缓冲区ByteBuffer、CharBuffer ..... 各种类型的buffer，用对应类型的数组存数据
  Selector：Selector运行单线程处理多个channel，若channel处理流量较小时，使用单个Selector处理多个channel是个很好的选择，要使用Selector得向Selector
  注册channel，然后调用Selector.select()方法，该方法会一直阻塞到某个注册的channel有事件是就绪态了，然后线程就可以处理就绪的channel事件。
=========================NIO读文件===========================
File file=new File("B:\\test.text");  
FileOutputStream fos=new FileOutputStream(file);
FileChannel fosChannel=fos.getChannel();
ByteBuffer byteBuffer=ByteBuffer.allocate(1024);
int read=0;
while(read!=-1){
  read=fosChannel.read(byteBuffer);
  byteBuffer.flip();//移动反转position
  while(byteBuffer.hasRemaining()){
    sout((char)byteBuffer.get());
  }
  byteBuffer.compact();
}
//上述代码会将file文件的内容以单个字符形式打出
=========================NIO读文件===========================

=========================NIO写文件===========================
File file=new File("B:\\test.text");
FileOutputStream fos=new FileOutputStream(file);
FileChannel fileChannel=fos.getChannel();
ByteBuffer byffer=ByteBuffer.allocate(1024);
byffer.put("hello".getBytes());
byffer.flip();
fileChannel.write(byffer);
fileChannel.close();
fos.close();

=========================NIO写文件===========================

</pre>

## **NIO TCP应用**
<pre>
SocketChannel：套接字管道，NIO的channel可通过配置其阻塞行为以实现非阻塞信道：channel.configureBlocking(false);在非阻塞通道上调用一个方法时，
总是会立刻返回，这类调用的返回值指示了请求调用的操作的完成程度，例如在一个非阻塞ServerSocketChannel上调用accept方法，如果有连接接入，则返回客户端
SocketChannel，否则返回null，而非阻塞式等待返回。
/** client端 **/
ByteBuffer bff=ByteBuffer.allocate(1024);
SocketChannel socketChannel = SocketChannel.open();
socketChannel.configureBlocking(false);
socketChannel.connect(new InetSocketAddress("localhost",8080));
if(socketChannel.finishConnect()){
  int i=0;
  while(true){
    TimeUnit.SECONDS.sleep(1);
    String info="info this is the "+ i+++" info from client ";
    bff.clear();
    bff.put(info.getBytes());
    bff.filp();
    while(bff.hasRemaining()){
      socketChannel.write(bff);
    }
  }
}
/** client端 **/

/** server端 **/
ByteBuffer bff=ByteBuffer.allocate(1024);
ServerSocket serverSocket=null;
InputStream ips=null;
serverSocket=new ServerSocket(8003);
int recvMsgSize=0;
byte[]recvByte=new byte[1024];
while(true){
  Socket socket=serverSocket.accept();
  SocketAddress socketAddress=socket.getRemoteSocketAddress();
  System.out.println(socketAddress.toString());
  ips=socket.getInputStream();
  while((recvMsgSize=ips.read(recvBytes)!=-1){
    byte[]temp=new byte[recvMsgSize];
    System.array.copy(recvBytes,0,temp,0,recvMsgSize);
    System.out.println(new String(temp));
  }
}
/** server端 **/
server端while循环accept等待客户端请求连接，accept通过后，socket获取输入流，client端connect连接服务端，当SocketChannel.finishConnect();便通过
channel.wirte(ByteBuffer);写数据。这里的server端并没有使用Selector而是使用了阻塞accept，读取和分发需要一个方法阻塞等待，直到至少一个信道可以进行
IO操作，并告知是哪一个信道.NIO的selector作用便是这个，多路开关选择器，一个选择器可管理多个信道上的IO操作

</pre>











